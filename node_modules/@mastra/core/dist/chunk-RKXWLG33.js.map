{"version":3,"sources":["../src/llm/model/gateways/base.ts"],"names":[],"mappings":";AAiBO,IAAe,qBAAf,MAAkC;AAkCzC","file":"chunk-RKXWLG33.js","sourcesContent":["/**\n * Base class for model gateway providers\n * Gateways fetch provider configurations and build URLs for model access\n */\n\nimport type { LanguageModelV2 } from '@ai-sdk/provider-v5';\n\nexport interface ProviderConfig {\n  url?: string;\n  apiKeyHeader?: string;\n  apiKeyEnvVar: string | string[];\n  name: string;\n  models: string[];\n  docUrl?: string; // Optional documentation URL\n  gateway: string;\n}\n\nexport abstract class MastraModelGateway {\n  /**\n   * Name of the gateway provider\n   */\n  abstract readonly name: string;\n\n  /**\n   * Optional prefix for provider IDs\n   * If set, all providers from this gateway will be prefixed (e.g., \"netlify/openai\")\n   * Registry gateways (like models.dev) typically don't have a prefix\n   */\n  abstract readonly prefix?: string;\n\n  /**\n   * Fetch provider configurations from the gateway\n   * Should return providers in the standard format\n   */\n  abstract fetchProviders(): Promise<Record<string, ProviderConfig>>;\n\n  /**\n   * Build the URL for a specific model/provider combination\n   * @param modelId Full model ID (e.g., \"openai/gpt-4o\" or \"netlify/openai/gpt-4o\")\n   * @param envVars Environment variables available\n   * @returns URL string if this gateway can handle the model, false otherwise\n   */\n  abstract buildUrl(modelId: string, envVars: Record<string, string>): string | undefined | Promise<string | undefined>;\n\n  abstract getApiKey(modelId: string): Promise<string>;\n\n  abstract resolveLanguageModel(args: {\n    modelId: string;\n    providerId: string;\n    apiKey: string;\n  }): Promise<LanguageModelV2> | LanguageModelV2;\n}\n"]}